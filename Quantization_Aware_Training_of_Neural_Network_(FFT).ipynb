{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Quantization Aware Training of Neural Network (FFT).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUq5M37pHTC0"
      },
      "source": [
        "# Importing packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eQkG8aZ_k-_",
        "outputId": "e3bcf4a8-8b66-4421-c3d3-1a47d236a354"
      },
      "source": [
        "# Install the tensorflow module responsible for the optimization (if not installed)\n",
        "!pip install tensorflow_model_optimization"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_model_optimization\n",
            "  Downloading tensorflow_model_optimization-0.6.0-py2.py3-none-any.whl (211 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▌                              | 10 kB 22.0 MB/s eta 0:00:01\r\u001b[K     |███                             | 20 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 30 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 40 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 61 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 81 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 92 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 184 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 194 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 204 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 211 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.15.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (0.1.6)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.19.5)\n",
            "Installing collected packages: tensorflow-model-optimization\n",
            "Successfully installed tensorflow-model-optimization-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49mntfS3_pzT"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5AnXOVqHX6l"
      },
      "source": [
        "# Preparing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlbj2XDD_p1p"
      },
      "source": [
        "# Generate batches of random values\n",
        "def randomSignal(number_batches, timesteps_per_batch=32):\n",
        "  signal = []\n",
        "\n",
        "  for i in range(number_batches):\n",
        "    l=[]\n",
        "    for j in range(timesteps_per_batch):\n",
        "      l.append((random.random()-0.5)*2)\n",
        "    signal.append(l)\n",
        "\n",
        "  return signal"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yEHs_pp_p4I"
      },
      "source": [
        "nbatches = 1000000    # Number of batches\n",
        "timesteps = 32       # Number of values in each batch\n",
        "data = randomSignal(nbatches, timesteps_per_batch=timesteps)\n",
        "data = np.array(data)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YMsFuse_p6h"
      },
      "source": [
        "# Calculate the Fast Fourier Transform of the generated data\n",
        "# This is the function we will try to imitate using NN (just for fun !)\n",
        "ffts = []\n",
        "for i in data:\n",
        "  x=np.fft.rfft(i)\n",
        "  ffts.append(x)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVnAJWZB_p86"
      },
      "source": [
        "ffts_real=[]   # The real parts of the ffts\n",
        "ffts_imag=[]   # The imaginary parts of the ffts\n",
        "for i in ffts:\n",
        "  y=[]\n",
        "  x=[]\n",
        "  for j in i:\n",
        "    y.append(j.real)\n",
        "    x.append(j.imag)\n",
        "  ffts_real.append(y)\n",
        "  ffts_imag.append(x)\n",
        "\n",
        "ffts_real = np.array(ffts_real)\n",
        "ffts_imag = np.array(ffts_imag)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjCg3Gow_p-3"
      },
      "source": [
        "# Calculate the ground truth output of the FFT function (labels)\n",
        "ffts_test = np.fft.rfft(data)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsnxHaVh_qBa"
      },
      "source": [
        "# decompose the test ffts to real parts and imaginary parts\n",
        "ffts_real_test = ffts_test.real\n",
        "ffts_imag_test = ffts_test.imag"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e16vOoLHcPK"
      },
      "source": [
        "# Training traditional models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gRVzIoV_qDq",
        "outputId": "50deb9ca-5fed-4de7-f291-bd6ee6edda57"
      },
      "source": [
        "# Model for learning the real part of the ffts\n",
        "model_real = Sequential()\n",
        "model_real.add(Dense(int(timesteps/2)+1, use_bias=False))\n",
        "\n",
        "model_real.compile(optimizer='adam',loss='mse')\n",
        "model_real.fit(data, ffts_real, epochs=10, batch_size=1024, validation_split=0.3)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 3.1107 - val_loss: 1.1280\n",
            "Epoch 2/10\n",
            "684/684 [==============================] - 1s 2ms/step - loss: 0.4777 - val_loss: 0.1255\n",
            "Epoch 3/10\n",
            "684/684 [==============================] - 1s 2ms/step - loss: 0.0435 - val_loss: 0.0069\n",
            "Epoch 4/10\n",
            "684/684 [==============================] - 1s 2ms/step - loss: 0.0019 - val_loss: 1.3384e-04\n",
            "Epoch 5/10\n",
            "684/684 [==============================] - 1s 2ms/step - loss: 2.7310e-05 - val_loss: 5.8619e-07\n",
            "Epoch 6/10\n",
            "684/684 [==============================] - 1s 2ms/step - loss: 8.7981e-08 - val_loss: 3.0928e-10\n",
            "Epoch 7/10\n",
            "684/684 [==============================] - 1s 2ms/step - loss: 4.9992e-11 - val_loss: 1.6855e-11\n",
            "Epoch 8/10\n",
            "684/684 [==============================] - 1s 2ms/step - loss: 1.2711e-11 - val_loss: 9.4639e-12\n",
            "Epoch 9/10\n",
            "684/684 [==============================] - 1s 2ms/step - loss: 7.0624e-12 - val_loss: 5.0950e-12\n",
            "Epoch 10/10\n",
            "684/684 [==============================] - 1s 2ms/step - loss: 3.8028e-12 - val_loss: 2.7476e-12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f085c8d2610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q52u0c0yBoZJ",
        "outputId": "970c379f-edb5-42e7-f000-6a4a8f72ab88"
      },
      "source": [
        "# Model for learning the imaginary part of the ffts\n",
        "model_imag = Sequential()\n",
        "model_imag.add(Dense(int(timesteps/2)+1, use_bias = False))\n",
        "\n",
        "model_imag.compile(optimizer='adam',loss='mse')\n",
        "model_imag.fit(data, ffts_imag, epochs=10, batch_size=1024, validation_split=0.3)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "684/684 [==============================] - 2s 2ms/step - loss: 2.3993 - val_loss: 0.8342\n",
            "Epoch 2/10\n",
            "684/684 [==============================] - 1s 2ms/step - loss: 0.3449 - val_loss: 0.0859\n",
            "Epoch 3/10\n",
            "684/684 [==============================] - 1s 2ms/step - loss: 0.0291 - val_loss: 0.0043\n",
            "Epoch 4/10\n",
            "684/684 [==============================] - 1s 2ms/step - loss: 0.0011 - val_loss: 7.5784e-05\n",
            "Epoch 5/10\n",
            "684/684 [==============================] - 1s 2ms/step - loss: 1.5136e-05 - val_loss: 2.9131e-07\n",
            "Epoch 6/10\n",
            "684/684 [==============================] - 1s 2ms/step - loss: 4.2733e-08 - val_loss: 1.3551e-10\n",
            "Epoch 7/10\n",
            "684/684 [==============================] - 1s 2ms/step - loss: 2.8102e-11 - val_loss: 1.3046e-11\n",
            "Epoch 8/10\n",
            "684/684 [==============================] - 1s 2ms/step - loss: 9.8030e-12 - val_loss: 7.1537e-12\n",
            "Epoch 9/10\n",
            "684/684 [==============================] - 1s 2ms/step - loss: 5.3795e-12 - val_loss: 3.8608e-12\n",
            "Epoch 10/10\n",
            "684/684 [==============================] - 1s 2ms/step - loss: 2.9008e-12 - val_loss: 2.0737e-12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0881c57210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBDYvi_NHocw"
      },
      "source": [
        "# Training Quantization Aware Training Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTUKN6ps_qF8",
        "outputId": "d000332a-b718-4038-efd1-d8376d1430d4"
      },
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "quantize_model_real = tfmot.quantization.keras.quantize_model\n",
        "\n",
        "# q_aware stands for for quantization aware.\n",
        "q_aware_model_real = quantize_model_real(model_real)\n",
        "\n",
        "# The QAT model requires a recompile.\n",
        "q_aware_model_real.compile(optimizer='adam',\n",
        "              loss=\"mse\")\n",
        "\n",
        "q_aware_model_real.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "quantize_layer (QuantizeLaye (None, 32)                3         \n",
            "_________________________________________________________________\n",
            "quant_dense (QuantizeWrapper (None, 17)                549       \n",
            "=================================================================\n",
            "Total params: 552\n",
            "Trainable params: 544\n",
            "Non-trainable params: 8\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8-T8CzvBrid",
        "outputId": "f00262a3-6588-4c60-a4ce-bf1dc5d2a1dd"
      },
      "source": [
        "quantize_model_imag = tfmot.quantization.keras.quantize_model\n",
        "\n",
        "# q_aware stands for for quantization aware.\n",
        "q_aware_model_imag = quantize_model_imag(model_imag)\n",
        "\n",
        "# The QAT model requires a recompile.\n",
        "q_aware_model_imag.compile(optimizer='adam',\n",
        "              loss=\"mse\")\n",
        "\n",
        "q_aware_model_imag.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "quantize_layer_1 (QuantizeLa (None, 32)                3         \n",
            "_________________________________________________________________\n",
            "quant_dense_1 (QuantizeWrapp (None, 17)                549       \n",
            "=================================================================\n",
            "Total params: 552\n",
            "Trainable params: 544\n",
            "Non-trainable params: 8\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cltnd2Vr_qIE",
        "outputId": "fe77b054-ae76-455c-8890-7800b4a4c3c7"
      },
      "source": [
        "# Train the QAT model (real part)\n",
        "q_aware_model_real.fit(data, ffts_real, batch_size=1024, epochs=10, validation_split=0.3)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.0092 - val_loss: 0.0025\n",
            "Epoch 2/10\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.0015 - val_loss: 0.0011\n",
            "Epoch 3/10\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 0.0010 - val_loss: 9.2732e-04\n",
            "Epoch 4/10\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 9.2707e-04 - val_loss: 9.2192e-04\n",
            "Epoch 5/10\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 9.1220e-04 - val_loss: 9.1183e-04\n",
            "Epoch 6/10\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 9.1012e-04 - val_loss: 8.9679e-04\n",
            "Epoch 7/10\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 9.1002e-04 - val_loss: 9.0937e-04\n",
            "Epoch 8/10\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 9.1149e-04 - val_loss: 9.0701e-04\n",
            "Epoch 9/10\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 9.0990e-04 - val_loss: 8.9366e-04\n",
            "Epoch 10/10\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 9.0878e-04 - val_loss: 9.2103e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f08604ed250>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6TJkpZH_qKZ",
        "outputId": "84b7ce41-f9e2-414b-c8c1-22fe21787cfb"
      },
      "source": [
        "# Train the QAT model (imaginary part)\n",
        "q_aware_model_imag.fit(data, ffts_imag, batch_size=1024, epochs=10, validation_split=0.3)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "684/684 [==============================] - 3s 3ms/step - loss: 0.0026 - val_loss: 9.8830e-04\n",
            "Epoch 2/10\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 7.2314e-04 - val_loss: 6.3670e-04\n",
            "Epoch 3/10\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 5.7672e-04 - val_loss: 5.8154e-04\n",
            "Epoch 4/10\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 5.5611e-04 - val_loss: 5.5836e-04\n",
            "Epoch 5/10\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 5.5386e-04 - val_loss: 5.5696e-04\n",
            "Epoch 6/10\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 5.5332e-04 - val_loss: 5.7548e-04\n",
            "Epoch 7/10\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 5.5397e-04 - val_loss: 5.8127e-04\n",
            "Epoch 8/10\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 5.5501e-04 - val_loss: 5.7348e-04\n",
            "Epoch 9/10\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 5.5401e-04 - val_loss: 5.8302e-04\n",
            "Epoch 10/10\n",
            "684/684 [==============================] - 2s 3ms/step - loss: 5.5463e-04 - val_loss: 5.6303e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f088c896e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTyL4J3nHDqh"
      },
      "source": [
        "# Evaluating performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bG_H0XEJFcld"
      },
      "source": [
        "nbatches = 100000    # Number of batches\n",
        "timesteps = 32       # Number of values in each batch\n",
        "test_data = randomSignal(nbatches, timesteps_per_batch=timesteps)\n",
        "test_data = np.array(data)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m00i6_gVFhXk"
      },
      "source": [
        "# Calculate the ground truth output of the FFT function (labels)\n",
        "ffts_test = np.fft.rfft(test_data)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIzWWhk1Fhad"
      },
      "source": [
        "# decompose the test ffts to real parts and imaginary parts\n",
        "ffts_real_test = ffts_test.real\n",
        "ffts_imag_test = ffts_test.imag"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twGhyznjHBx1",
        "outputId": "605d2fba-e97f-4680-a413-9e22243c4a58"
      },
      "source": [
        "baseline_model_real_loss = model_real.evaluate(\n",
        "    test_data, ffts_real_test, verbose=1)\n",
        "\n",
        "q_aware_model_real_loss = q_aware_model_real.evaluate(\n",
        "   test_data, ffts_real_test, verbose=1)\n",
        "\n",
        "print('Baseline test MSE:', baseline_model_real_loss)\n",
        "print('Quant test MSE:', q_aware_model_real_loss)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31250/31250 [==============================] - 44s 1ms/step - loss: 2.7393e-12\n",
            "31250/31250 [==============================] - 50s 2ms/step - loss: 9.2501e-04\n",
            "Baseline test MSE: 2.7393456426827445e-12\n",
            "Quant test MSE: 0.0009250055300071836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bju8HBUKFHje",
        "outputId": "15ff64e4-a8eb-4c35-ce48-a09bf569a46d"
      },
      "source": [
        "baseline_model_imag_loss = model_imag.evaluate(\n",
        "    test_data, ffts_imag_test, verbose=1)\n",
        "\n",
        "q_aware_model_imag_loss = q_aware_model_imag.evaluate(\n",
        "   test_data, ffts_imag_test, verbose=1)\n",
        "\n",
        "print('Baseline test MSE:', baseline_model_imag_loss)\n",
        "print('Quant test MSE:', q_aware_model_imag_loss)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31250/31250 [==============================] - 44s 1ms/step - loss: 2.0690e-12\n",
            "31250/31250 [==============================] - 48s 2ms/step - loss: 5.5886e-04\n",
            "Baseline test MSE: 2.068955467018907e-12\n",
            "Quant test MSE: 0.0005588564672507346\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMJtejxJHzCu"
      },
      "source": [
        "# Performing Quantization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEcQ7ziK_qMw",
        "outputId": "cc7aaab3-cb9a-421d-fcf3-7de28e9784d7"
      },
      "source": [
        "# This is when the quantization takes place\n",
        "converter_real = tf.lite.TFLiteConverter.from_keras_model(q_aware_model_real)\n",
        "converter_real.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "quantized_tflite_model_real = converter_real.convert()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as dense_layer_call_and_return_conditional_losses, dense_layer_call_fn, dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp0zsjawku/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp0zsjawku/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9hyqCmP_qO3",
        "outputId": "d290deb9-f529-48c1-a76e-9ead5f164590"
      },
      "source": [
        "# This is when the quantization takes place\n",
        "converter_imag = tf.lite.TFLiteConverter.from_keras_model(q_aware_model_imag)\n",
        "converter_imag.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "quantized_tflite_model_imag = converter_imag.convert()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as dense_1_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp_ky_yigl/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp_ky_yigl/assets\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}